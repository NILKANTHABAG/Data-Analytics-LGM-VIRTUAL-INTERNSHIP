{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Intern at Let's Grow More LGMVIP \n",
    "\n",
    "# More Advanced Level Task\n",
    "\n",
    "# ML Facial recognition to detect mood and suggest songs accordingly\n",
    "\n",
    "## Part1 - TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:27.082946Z",
     "iopub.status.busy": "2022-03-21T09:16:27.081954Z",
     "iopub.status.idle": "2022-03-21T09:16:32.021070Z",
     "shell.execute_reply": "2022-03-21T09:16:32.020296Z",
     "shell.execute_reply.started": "2022-03-21T09:16:27.082800Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Linraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:32.023122Z",
     "iopub.status.busy": "2022-03-21T09:16:32.022827Z",
     "iopub.status.idle": "2022-03-21T09:16:33.673260Z",
     "shell.execute_reply": "2022-03-21T09:16:33.672501Z",
     "shell.execute_reply.started": "2022-03-21T09:16:32.023085Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:33.674952Z",
     "iopub.status.busy": "2022-03-21T09:16:33.674689Z",
     "iopub.status.idle": "2022-03-21T09:16:33.707315Z",
     "shell.execute_reply": "2022-03-21T09:16:33.706668Z",
     "shell.execute_reply.started": "2022-03-21T09:16:33.674916Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = '../input/fer2013/train'\n",
    "test_dir = '../input/fer2013/test'\n",
    "\n",
    "row, col = 48, 48\n",
    "classes = 7\n",
    "\n",
    "def count_exp(path, set_):\n",
    "    dict_ = {}\n",
    "    for expression in os.listdir(path):\n",
    "        dir_ = path +\"/\" +expression\n",
    "        dict_[expression] = len(os.listdir(dir_))\n",
    "    df = pd.DataFrame(dict_, index=[set_])\n",
    "    return df\n",
    "train_count = count_exp(train_dir, 'train')\n",
    "test_count = count_exp(test_dir, 'test')\n",
    "print(train_count)\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of number of images in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:33.709737Z",
     "iopub.status.busy": "2022-03-21T09:16:33.709486Z",
     "iopub.status.idle": "2022-03-21T09:16:33.934426Z",
     "shell.execute_reply": "2022-03-21T09:16:33.933664Z",
     "shell.execute_reply.started": "2022-03-21T09:16:33.709703Z"
    }
   },
   "outputs": [],
   "source": [
    "train_count.transpose().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLot of number of images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:33.935670Z",
     "iopub.status.busy": "2022-03-21T09:16:33.935429Z",
     "iopub.status.idle": "2022-03-21T09:16:34.197704Z",
     "shell.execute_reply": "2022-03-21T09:16:34.196983Z",
     "shell.execute_reply.started": "2022-03-21T09:16:33.935636Z"
    }
   },
   "outputs": [],
   "source": [
    "test_count.transpose().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:34.201365Z",
     "iopub.status.busy": "2022-03-21T09:16:34.200977Z",
     "iopub.status.idle": "2022-03-21T09:16:34.657770Z",
     "shell.execute_reply": "2022-03-21T09:16:34.655752Z",
     "shell.execute_reply.started": "2022-03-21T09:16:34.201313Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "plt.figure(figsize=(14,22))\n",
    "i = 1\n",
    "for expression in os.listdir(train_dir):\n",
    "    img = load_img((train_dir+\"/\" + expression + \"/\" + os.listdir(train_dir +\"/\"+ expression)[1]))\n",
    "    plt.subplot(1,7,i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(expression)\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:34.659097Z",
     "iopub.status.busy": "2022-03-21T09:16:34.658824Z",
     "iopub.status.idle": "2022-03-21T09:16:36.304444Z",
     "shell.execute_reply": "2022-03-21T09:16:36.303630Z",
     "shell.execute_reply.started": "2022-03-21T09:16:34.659059Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_gen = ImageDataGenerator(rotation_range=20,\n",
    "                              rescale=1./255,\n",
    "                              shear_range=0.1,\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1)\n",
    "\n",
    "training_data = train_gen.flow_from_directory(train_dir,\n",
    "                                             target_size=(224,224),\n",
    "                                             batch_size=64,\n",
    "                                             color_mode = \"grayscale\",\n",
    "                                             class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:36.306289Z",
     "iopub.status.busy": "2022-03-21T09:16:36.305876Z",
     "iopub.status.idle": "2022-03-21T09:16:36.730736Z",
     "shell.execute_reply": "2022-03-21T09:16:36.730002Z",
     "shell.execute_reply.started": "2022-03-21T09:16:36.306249Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_data = valid_gen.flow_from_directory(test_dir,\n",
    "                                          target_size=(224,224),\n",
    "                                          batch_size=64,\n",
    "                                          color_mode='grayscale',\n",
    "                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling vgg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:36.732517Z",
     "iopub.status.busy": "2022-03-21T09:16:36.732107Z",
     "iopub.status.idle": "2022-03-21T09:16:38.054286Z",
     "shell.execute_reply": "2022-03-21T09:16:38.053502Z",
     "shell.execute_reply.started": "2022-03-21T09:16:36.732476Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "vgg = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:38.057131Z",
     "iopub.status.busy": "2022-03-21T09:16:38.056833Z",
     "iopub.status.idle": "2022-03-21T09:16:38.135301Z",
     "shell.execute_reply": "2022-03-21T09:16:38.134590Z",
     "shell.execute_reply.started": "2022-03-21T09:16:38.057094Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input = Input(shape=(224,224,1))\n",
    "\n",
    "conv = Conv2D(3, kernel_size=(3,3), padding='same')(input)\n",
    "\n",
    "vgg = vgg(conv)\n",
    "    \n",
    "x = Flatten()(vgg)\n",
    "\n",
    "pred = Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:38.136699Z",
     "iopub.status.busy": "2022-03-21T09:16:38.136456Z",
     "iopub.status.idle": "2022-03-21T09:16:38.147498Z",
     "shell.execute_reply": "2022-03-21T09:16:38.146767Z",
     "shell.execute_reply.started": "2022-03-21T09:16:38.136665Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:38.149633Z",
     "iopub.status.busy": "2022-03-21T09:16:38.148690Z",
     "iopub.status.idle": "2022-03-21T09:16:38.165135Z",
     "shell.execute_reply": "2022-03-21T09:16:38.164454Z",
     "shell.execute_reply.started": "2022-03-21T09:16:38.149593Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer = opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T09:16:38.166768Z",
     "iopub.status.busy": "2022-03-21T09:16:38.166520Z",
     "iopub.status.idle": "2022-03-21T14:15:43.790933Z",
     "shell.execute_reply": "2022-03-21T14:15:43.790138Z",
     "shell.execute_reply.started": "2022-03-21T09:16:38.166734Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(training_data, epochs=100, validation_data = valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:16:44.875023Z",
     "iopub.status.busy": "2022-03-21T14:16:44.874207Z",
     "iopub.status.idle": "2022-03-21T14:16:45.202506Z",
     "shell.execute_reply": "2022-03-21T14:16:45.201716Z",
     "shell.execute_reply.started": "2022-03-21T14:16:44.874957Z"
    }
   },
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:16:51.684309Z",
     "iopub.status.busy": "2022-03-21T14:16:51.683881Z",
     "iopub.status.idle": "2022-03-21T14:19:22.246770Z",
     "shell.execute_reply": "2022-03-21T14:19:22.246110Z",
     "shell.execute_reply.started": "2022-03-21T14:16:51.684269Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(training_data)\n",
    "test_loss, test_acc = model.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:21:22.070505Z",
     "iopub.status.busy": "2022-03-21T14:21:22.070220Z",
     "iopub.status.idle": "2022-03-21T14:21:22.285382Z",
     "shell.execute_reply": "2022-03-21T14:21:22.284700Z",
     "shell.execute_reply.started": "2022-03-21T14:21:22.070474Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "test_img = image.load_img('../input/fer2013/test/angry/PrivateTest_13278552.jpg',target_size = (224,224),color_mode = \"grayscale\")\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:21:37.218591Z",
     "iopub.status.busy": "2022-03-21T14:21:37.217759Z",
     "iopub.status.idle": "2022-03-21T14:21:37.682346Z",
     "shell.execute_reply": "2022-03-21T14:21:37.681522Z",
     "shell.execute_reply.started": "2022-03-21T14:21:37.218531Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n",
    "\n",
    "test_img = np.expand_dims(test_img,axis = 0)\n",
    "test_img = test_img.reshape(1,224,224,1)\n",
    "result = model.predict(test_img)\n",
    "result = list(result[0])\n",
    "\n",
    "img_index = result.index(max(result))\n",
    "print(label_dict[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:21:45.527921Z",
     "iopub.status.busy": "2022-03-21T14:21:45.527648Z",
     "iopub.status.idle": "2022-03-21T14:21:45.697760Z",
     "shell.execute_reply": "2022-03-21T14:21:45.697023Z",
     "shell.execute_reply.started": "2022-03-21T14:21:45.527891Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('model_optimal.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2 - TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing depandancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:23:59.100271Z",
     "iopub.status.busy": "2022-03-21T14:23:59.100000Z",
     "iopub.status.idle": "2022-03-21T14:24:10.051639Z",
     "shell.execute_reply": "2022-03-21T14:24:10.050821Z",
     "shell.execute_reply.started": "2022-03-21T14:23:59.100240Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:25:05.033323Z",
     "iopub.status.busy": "2022-03-21T14:25:05.033044Z",
     "iopub.status.idle": "2022-03-21T14:25:05.356009Z",
     "shell.execute_reply": "2022-03-21T14:25:05.355255Z",
     "shell.execute_reply.started": "2022-03-21T14:25:05.033294Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from mtcnn import MTCNN  # helps in detecting faces from image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:26:12.163425Z",
     "iopub.status.busy": "2022-03-21T14:26:12.163159Z",
     "iopub.status.idle": "2022-03-21T14:26:12.671332Z",
     "shell.execute_reply": "2022-03-21T14:26:12.670527Z",
     "shell.execute_reply.started": "2022-03-21T14:26:12.163396Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('./model_optimal.h5')\n",
    "print('Model Loaded 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:30:13.605334Z",
     "iopub.status.busy": "2022-03-21T14:30:13.604720Z",
     "iopub.status.idle": "2022-03-21T14:30:16.402908Z",
     "shell.execute_reply": "2022-03-21T14:30:16.402223Z",
     "shell.execute_reply.started": "2022-03-21T14:30:13.605290Z"
    }
   },
   "outputs": [],
   "source": [
    "img = 'https://static-bebeautiful-in.unileverservices.com/Unlock-flawless-skin_MobileHomeFeature.jpg'\n",
    "try:\n",
    "    image = plt.imread(img)\n",
    "except SyntaxError:\n",
    "    image = plt.imread(img, format='jpg')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:30:58.341924Z",
     "iopub.status.busy": "2022-03-21T14:30:58.341374Z",
     "iopub.status.idle": "2022-03-21T14:30:59.987385Z",
     "shell.execute_reply": "2022-03-21T14:30:59.986723Z",
     "shell.execute_reply.started": "2022-03-21T14:30:58.341886Z"
    }
   },
   "outputs": [],
   "source": [
    "detect = MTCNN()\n",
    "results = detect.detect_faces(image)\n",
    "\n",
    "x1, y1, width, height = results[0]['box']\n",
    "x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "face = image[y1:y2, x1:x2]\n",
    "plt.imshow(face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:31:31.357363Z",
     "iopub.status.busy": "2022-03-21T14:31:31.356877Z",
     "iopub.status.idle": "2022-03-21T14:31:31.361808Z",
     "shell.execute_reply": "2022-03-21T14:31:31.360901Z",
     "shell.execute_reply.started": "2022-03-21T14:31:31.357325Z"
    }
   },
   "outputs": [],
   "source": [
    "test_image = np.resize(face, (224,224,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:32:18.781810Z",
     "iopub.status.busy": "2022-03-21T14:32:18.781349Z",
     "iopub.status.idle": "2022-03-21T14:32:18.839499Z",
     "shell.execute_reply": "2022-03-21T14:32:18.838725Z",
     "shell.execute_reply.started": "2022-03-21T14:32:18.781769Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n",
    "\n",
    "test_img = np.expand_dims(test_image, axis = 0)\n",
    "test_img = test_img.reshape(-1,224,224,1)\n",
    "result = model.predict(test_img)\n",
    "result = list(result[0])\n",
    "\n",
    "img_index = result.index(max(result))\n",
    "emotion = label_dict[img_index]\n",
    "print(emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Song Playing as per mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-21T14:35:48.485992Z",
     "iopub.status.busy": "2022-03-21T14:35:48.485716Z",
     "iopub.status.idle": "2022-03-21T14:35:48.490691Z",
     "shell.execute_reply": "2022-03-21T14:35:48.489984Z",
     "shell.execute_reply.started": "2022-03-21T14:35:48.485956Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "song_path = '../input/emotion-audio-files/Ringtones'\n",
    "song = os.path.join(song_path,emotion)\n",
    "print(f'Playing {emotion} song')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>THE END</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
